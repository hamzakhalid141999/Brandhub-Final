{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a63TRCk8bhy",
    "outputId": "490760ba-f83d-4fee-beab-62c999b45d13"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2804/2804 [01:08<00:00, 41.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2465/2465 [00:33<00:00, 73.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5269\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "DATADIR = \"C:/Users/dell/Desktop/New folder\"\n",
    "\n",
    "CATEGORIES = [\"Eastern\", \"Western\"] \n",
    "\n",
    "training_data = []\n",
    "IMG_SIZE=60\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:  # iterate over categories\n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path to top and bottom\n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=top 1=bottom\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image per top and bottom\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  #handle any exception\n",
    "                pass\n",
    "                \n",
    "           \n",
    "\n",
    "create_training_data() #store training data\n",
    "\n",
    "print(len(training_data)) #print len of training data\n",
    "random.shuffle(training_data) #shuffle training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yswZOveM8bh6"
   },
   "outputs": [],
   "source": [
    "X = [] #features\n",
    "y = [] #lables\n",
    "\n",
    "#store features(images) and label in X and y respectively\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1) # -1 represents how many features we have ,resize images to 60x60, 1 is because of grayscale\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CQxDL27H8bh-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "\n",
    "def trainModel(X,y):\n",
    "    X = np.array(X/255.0) #scale data by dividing with max value and convert to numpy array\n",
    "    y=np.array(y)\n",
    "\n",
    "    model = Sequential() \n",
    "\n",
    "    #add 2 convolutional layers\n",
    "    model.add(Conv2D(64, (3, 3), input_shape=X.shape[1:])) # 1: means we ignore the -1 in -1x60x60x1 because that doesn't contribute to shape of images \n",
    "    model.add(Activation('relu')) #Rectified Linear Unit Activation\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3))) #filter of 64 with 3x3 kernel\n",
    "    model.add(Activation('relu')) #Rectified Linear Unit Activation\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())  # convert 3D feature maps to 1D feature vectors\n",
    "\n",
    "    model.add(Dense(64)) #adding a dense layer with 64 neurons\n",
    "\n",
    "    model.add(Dense(1)) #final dense layer with 1 neuron to get 1 value\n",
    "    model.add(Activation('sigmoid')) #gives values between 0 and 1\n",
    "    #we use binary cross entropy cuz we have 2 categories\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy']) #use binray cross entropy as we have 2 classes\n",
    "    \n",
    "   \n",
    "    model.fit(X, y, batch_size=32, epochs=10, validation_split=0.3) #test on 30% of data\n",
    "    model.save('EasternWestern_model') #save model in this folder to be used later on\n",
    "    loaded_model=keras.models.load_model(\"EasternWestern_model\") #load the saved model\n",
    "    np.testing.assert_allclose(model.predict(X),loaded_model.predict(X)) #check if the saved and loaded model are same. If no exception, it means they're same\n",
    "   \n",
    "    \n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Goh3RbdI8biF",
    "outputId": "aa590671-f593-4db5-d2e6-fa5dcd54f872",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.56 - ETA: 9s - loss: 0.9701 - accuracy: 0.48 - ETA: 12s - loss: 0.8833 - accuracy: 0.458 - ETA: 13s - loss: 0.8596 - accuracy: 0.445 - ETA: 14s - loss: 0.8501 - accuracy: 0.425 - ETA: 15s - loss: 0.8416 - accuracy: 0.395 - ETA: 15s - loss: 0.8219 - accuracy: 0.401 - ETA: 15s - loss: 0.8064 - accuracy: 0.402 - ETA: 15s - loss: 0.7938 - accuracy: 0.409 - ETA: 15s - loss: 0.7834 - accuracy: 0.434 - ETA: 15s - loss: 0.7752 - accuracy: 0.443 - ETA: 15s - loss: 0.7681 - accuracy: 0.463 - ETA: 15s - loss: 0.7622 - accuracy: 0.471 - ETA: 15s - loss: 0.7573 - accuracy: 0.468 - ETA: 15s - loss: 0.7528 - accuracy: 0.475 - ETA: 15s - loss: 0.7486 - accuracy: 0.492 - ETA: 15s - loss: 0.7450 - accuracy: 0.501 - ETA: 15s - loss: 0.7418 - accuracy: 0.498 - ETA: 15s - loss: 0.7387 - accuracy: 0.501 - ETA: 14s - loss: 0.7364 - accuracy: 0.498 - ETA: 14s - loss: 0.7343 - accuracy: 0.500 - ETA: 14s - loss: 0.7323 - accuracy: 0.502 - ETA: 14s - loss: 0.7300 - accuracy: 0.506 - ETA: 14s - loss: 0.7279 - accuracy: 0.511 - ETA: 14s - loss: 0.7257 - accuracy: 0.516 - ETA: 14s - loss: 0.7241 - accuracy: 0.520 - ETA: 14s - loss: 0.7216 - accuracy: 0.525 - ETA: 13s - loss: 0.7194 - accuracy: 0.529 - ETA: 13s - loss: 0.7199 - accuracy: 0.524 - ETA: 13s - loss: 0.7166 - accuracy: 0.530 - ETA: 13s - loss: 0.7157 - accuracy: 0.528 - ETA: 13s - loss: 0.7150 - accuracy: 0.530 - ETA: 13s - loss: 0.7133 - accuracy: 0.534 - ETA: 13s - loss: 0.7132 - accuracy: 0.534 - ETA: 13s - loss: 0.7156 - accuracy: 0.530 - ETA: 12s - loss: 0.7143 - accuracy: 0.533 - ETA: 12s - loss: 0.7136 - accuracy: 0.533 - ETA: 12s - loss: 0.7121 - accuracy: 0.536 - ETA: 12s - loss: 0.7108 - accuracy: 0.538 - ETA: 12s - loss: 0.7092 - accuracy: 0.540 - ETA: 12s - loss: 0.7095 - accuracy: 0.538 - ETA: 12s - loss: 0.7086 - accuracy: 0.539 - ETA: 11s - loss: 0.7073 - accuracy: 0.543 - ETA: 11s - loss: 0.7060 - accuracy: 0.546 - ETA: 11s - loss: 0.7047 - accuracy: 0.552 - ETA: 11s - loss: 0.7042 - accuracy: 0.552 - ETA: 11s - loss: 0.7038 - accuracy: 0.552 - ETA: 11s - loss: 0.7020 - accuracy: 0.554 - ETA: 10s - loss: 0.7006 - accuracy: 0.554 - ETA: 10s - loss: 0.6996 - accuracy: 0.556 - ETA: 10s - loss: 0.6994 - accuracy: 0.557 - ETA: 10s - loss: 0.6989 - accuracy: 0.557 - ETA: 10s - loss: 0.6976 - accuracy: 0.558 - ETA: 10s - loss: 0.6971 - accuracy: 0.560 - ETA: 10s - loss: 0.6965 - accuracy: 0.563 - ETA: 9s - loss: 0.6956 - accuracy: 0.564 - ETA: 9s - loss: 0.6942 - accuracy: 0.56 - ETA: 9s - loss: 0.6933 - accuracy: 0.56 - ETA: 9s - loss: 0.6924 - accuracy: 0.56 - ETA: 9s - loss: 0.6911 - accuracy: 0.56 - ETA: 9s - loss: 0.6909 - accuracy: 0.57 - ETA: 9s - loss: 0.6911 - accuracy: 0.56 - ETA: 8s - loss: 0.6892 - accuracy: 0.57 - ETA: 8s - loss: 0.6890 - accuracy: 0.57 - ETA: 8s - loss: 0.6913 - accuracy: 0.56 - ETA: 8s - loss: 0.6903 - accuracy: 0.57 - ETA: 8s - loss: 0.6897 - accuracy: 0.57 - ETA: 8s - loss: 0.6898 - accuracy: 0.57 - ETA: 7s - loss: 0.6897 - accuracy: 0.57 - ETA: 7s - loss: 0.6893 - accuracy: 0.57 - ETA: 7s - loss: 0.6877 - accuracy: 0.57 - ETA: 7s - loss: 0.6866 - accuracy: 0.57 - ETA: 7s - loss: 0.6868 - accuracy: 0.57 - ETA: 7s - loss: 0.6864 - accuracy: 0.58 - ETA: 6s - loss: 0.6847 - accuracy: 0.58 - ETA: 6s - loss: 0.6832 - accuracy: 0.58 - ETA: 6s - loss: 0.6828 - accuracy: 0.58 - ETA: 6s - loss: 0.6817 - accuracy: 0.58 - ETA: 6s - loss: 0.6806 - accuracy: 0.59 - ETA: 6s - loss: 0.6797 - accuracy: 0.59 - ETA: 5s - loss: 0.6780 - accuracy: 0.59 - ETA: 5s - loss: 0.6769 - accuracy: 0.59 - ETA: 5s - loss: 0.6762 - accuracy: 0.59 - ETA: 5s - loss: 0.6750 - accuracy: 0.59 - ETA: 5s - loss: 0.6745 - accuracy: 0.59 - ETA: 5s - loss: 0.6725 - accuracy: 0.59 - ETA: 4s - loss: 0.6719 - accuracy: 0.59 - ETA: 4s - loss: 0.6706 - accuracy: 0.60 - ETA: 4s - loss: 0.6693 - accuracy: 0.60 - ETA: 4s - loss: 0.6678 - accuracy: 0.60 - ETA: 4s - loss: 0.6665 - accuracy: 0.60 - ETA: 4s - loss: 0.6660 - accuracy: 0.60 - ETA: 3s - loss: 0.6658 - accuracy: 0.60 - ETA: 3s - loss: 0.6649 - accuracy: 0.60 - ETA: 3s - loss: 0.6635 - accuracy: 0.60 - ETA: 3s - loss: 0.6625 - accuracy: 0.61 - ETA: 3s - loss: 0.6610 - accuracy: 0.61 - ETA: 3s - loss: 0.6596 - accuracy: 0.61 - ETA: 2s - loss: 0.6587 - accuracy: 0.61 - ETA: 2s - loss: 0.6581 - accuracy: 0.61 - ETA: 2s - loss: 0.6560 - accuracy: 0.61 - ETA: 2s - loss: 0.6560 - accuracy: 0.61 - ETA: 2s - loss: 0.6561 - accuracy: 0.61 - ETA: 2s - loss: 0.6552 - accuracy: 0.61 - ETA: 1s - loss: 0.6532 - accuracy: 0.61 - ETA: 1s - loss: 0.6526 - accuracy: 0.61 - ETA: 1s - loss: 0.6524 - accuracy: 0.61 - ETA: 1s - loss: 0.6507 - accuracy: 0.62 - ETA: 1s - loss: 0.6486 - accuracy: 0.62 - ETA: 1s - loss: 0.6469 - accuracy: 0.62 - ETA: 0s - loss: 0.6462 - accuracy: 0.62 - ETA: 0s - loss: 0.6459 - accuracy: 0.62 - ETA: 0s - loss: 0.6470 - accuracy: 0.62 - ETA: 0s - loss: 0.6476 - accuracy: 0.62 - ETA: 0s - loss: 0.6461 - accuracy: 0.62 - ETA: 0s - loss: 0.6458 - accuracy: 0.62 - 22s 190ms/step - loss: 0.6458 - accuracy: 0.6269 - val_loss: 0.5502 - val_accuracy: 0.7337\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.5428 - accuracy: 0.75 - ETA: 9s - loss: 0.5228 - accuracy: 0.73 - ETA: 12s - loss: 0.5235 - accuracy: 0.739 - ETA: 13s - loss: 0.4973 - accuracy: 0.781 - ETA: 17s - loss: 0.5152 - accuracy: 0.756 - ETA: 18s - loss: 0.5212 - accuracy: 0.755 - ETA: 18s - loss: 0.5280 - accuracy: 0.745 - ETA: 19s - loss: 0.5259 - accuracy: 0.746 - ETA: 19s - loss: 0.5316 - accuracy: 0.736 - ETA: 19s - loss: 0.5436 - accuracy: 0.731 - ETA: 19s - loss: 0.5431 - accuracy: 0.730 - ETA: 19s - loss: 0.5460 - accuracy: 0.721 - ETA: 19s - loss: 0.5465 - accuracy: 0.721 - ETA: 19s - loss: 0.5501 - accuracy: 0.725 - ETA: 19s - loss: 0.5462 - accuracy: 0.722 - ETA: 19s - loss: 0.5478 - accuracy: 0.718 - ETA: 19s - loss: 0.5518 - accuracy: 0.718 - ETA: 19s - loss: 0.5577 - accuracy: 0.711 - ETA: 19s - loss: 0.5541 - accuracy: 0.713 - ETA: 19s - loss: 0.5545 - accuracy: 0.712 - ETA: 19s - loss: 0.5584 - accuracy: 0.706 - ETA: 19s - loss: 0.5622 - accuracy: 0.697 - ETA: 19s - loss: 0.5658 - accuracy: 0.697 - ETA: 18s - loss: 0.5576 - accuracy: 0.704 - ETA: 18s - loss: 0.5548 - accuracy: 0.705 - ETA: 18s - loss: 0.5531 - accuracy: 0.705 - ETA: 18s - loss: 0.5528 - accuracy: 0.704 - ETA: 17s - loss: 0.5541 - accuracy: 0.704 - ETA: 17s - loss: 0.5552 - accuracy: 0.701 - ETA: 17s - loss: 0.5564 - accuracy: 0.697 - ETA: 17s - loss: 0.5511 - accuracy: 0.705 - ETA: 17s - loss: 0.5482 - accuracy: 0.707 - ETA: 17s - loss: 0.5463 - accuracy: 0.705 - ETA: 16s - loss: 0.5452 - accuracy: 0.709 - ETA: 16s - loss: 0.5424 - accuracy: 0.714 - ETA: 16s - loss: 0.5382 - accuracy: 0.717 - ETA: 16s - loss: 0.5373 - accuracy: 0.719 - ETA: 16s - loss: 0.5367 - accuracy: 0.719 - ETA: 15s - loss: 0.5383 - accuracy: 0.718 - ETA: 15s - loss: 0.5388 - accuracy: 0.718 - ETA: 15s - loss: 0.5395 - accuracy: 0.716 - ETA: 15s - loss: 0.5414 - accuracy: 0.714 - ETA: 15s - loss: 0.5425 - accuracy: 0.712 - ETA: 14s - loss: 0.5426 - accuracy: 0.713 - ETA: 14s - loss: 0.5407 - accuracy: 0.715 - ETA: 14s - loss: 0.5415 - accuracy: 0.714 - ETA: 14s - loss: 0.5435 - accuracy: 0.712 - ETA: 13s - loss: 0.5435 - accuracy: 0.710 - ETA: 13s - loss: 0.5446 - accuracy: 0.711 - ETA: 13s - loss: 0.5438 - accuracy: 0.711 - ETA: 13s - loss: 0.5430 - accuracy: 0.712 - ETA: 12s - loss: 0.5428 - accuracy: 0.711 - ETA: 12s - loss: 0.5418 - accuracy: 0.712 - ETA: 12s - loss: 0.5422 - accuracy: 0.712 - ETA: 12s - loss: 0.5420 - accuracy: 0.713 - ETA: 11s - loss: 0.5404 - accuracy: 0.715 - ETA: 11s - loss: 0.5387 - accuracy: 0.716 - ETA: 11s - loss: 0.5395 - accuracy: 0.717 - ETA: 11s - loss: 0.5392 - accuracy: 0.716 - ETA: 10s - loss: 0.5376 - accuracy: 0.718 - ETA: 10s - loss: 0.5371 - accuracy: 0.719 - ETA: 10s - loss: 0.5348 - accuracy: 0.720 - ETA: 10s - loss: 0.5323 - accuracy: 0.722 - ETA: 10s - loss: 0.5325 - accuracy: 0.722 - ETA: 9s - loss: 0.5307 - accuracy: 0.724 - ETA: 9s - loss: 0.5291 - accuracy: 0.72 - ETA: 9s - loss: 0.5278 - accuracy: 0.72 - ETA: 9s - loss: 0.5282 - accuracy: 0.72 - ETA: 8s - loss: 0.5279 - accuracy: 0.72 - ETA: 8s - loss: 0.5258 - accuracy: 0.72 - ETA: 8s - loss: 0.5250 - accuracy: 0.72 - ETA: 8s - loss: 0.5254 - accuracy: 0.72 - ETA: 8s - loss: 0.5261 - accuracy: 0.72 - ETA: 7s - loss: 0.5277 - accuracy: 0.72 - ETA: 7s - loss: 0.5271 - accuracy: 0.72 - ETA: 7s - loss: 0.5261 - accuracy: 0.72 - ETA: 7s - loss: 0.5259 - accuracy: 0.72 - ETA: 7s - loss: 0.5261 - accuracy: 0.72 - ETA: 6s - loss: 0.5247 - accuracy: 0.72 - ETA: 6s - loss: 0.5260 - accuracy: 0.72 - ETA: 6s - loss: 0.5256 - accuracy: 0.72 - ETA: 6s - loss: 0.5246 - accuracy: 0.72 - ETA: 6s - loss: 0.5252 - accuracy: 0.72 - ETA: 5s - loss: 0.5248 - accuracy: 0.72 - ETA: 5s - loss: 0.5242 - accuracy: 0.73 - ETA: 5s - loss: 0.5247 - accuracy: 0.72 - ETA: 5s - loss: 0.5247 - accuracy: 0.72 - ETA: 5s - loss: 0.5258 - accuracy: 0.72 - ETA: 5s - loss: 0.5253 - accuracy: 0.72 - ETA: 4s - loss: 0.5259 - accuracy: 0.72 - ETA: 4s - loss: 0.5248 - accuracy: 0.72 - ETA: 4s - loss: 0.5242 - accuracy: 0.72 - ETA: 4s - loss: 0.5228 - accuracy: 0.73 - ETA: 4s - loss: 0.5216 - accuracy: 0.73 - ETA: 3s - loss: 0.5203 - accuracy: 0.73 - ETA: 3s - loss: 0.5206 - accuracy: 0.73 - ETA: 3s - loss: 0.5206 - accuracy: 0.73 - ETA: 3s - loss: 0.5199 - accuracy: 0.73 - ETA: 3s - loss: 0.5202 - accuracy: 0.73 - ETA: 2s - loss: 0.5206 - accuracy: 0.73 - ETA: 2s - loss: 0.5187 - accuracy: 0.73 - ETA: 2s - loss: 0.5184 - accuracy: 0.73 - ETA: 2s - loss: 0.5170 - accuracy: 0.73 - ETA: 2s - loss: 0.5184 - accuracy: 0.73 - ETA: 2s - loss: 0.5183 - accuracy: 0.73 - ETA: 1s - loss: 0.5173 - accuracy: 0.73 - ETA: 1s - loss: 0.5170 - accuracy: 0.73 - ETA: 1s - loss: 0.5179 - accuracy: 0.73 - ETA: 1s - loss: 0.5172 - accuracy: 0.73 - ETA: 1s - loss: 0.5165 - accuracy: 0.73 - ETA: 0s - loss: 0.5185 - accuracy: 0.73 - ETA: 0s - loss: 0.5172 - accuracy: 0.73 - ETA: 0s - loss: 0.5153 - accuracy: 0.73 - ETA: 0s - loss: 0.5144 - accuracy: 0.73 - ETA: 0s - loss: 0.5138 - accuracy: 0.73 - ETA: 0s - loss: 0.5132 - accuracy: 0.74 - 23s 201ms/step - loss: 0.5132 - accuracy: 0.7402 - val_loss: 0.5207 - val_accuracy: 0.7419\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.4402 - accuracy: 0.78 - ETA: 8s - loss: 0.5300 - accuracy: 0.70 - ETA: 11s - loss: 0.5089 - accuracy: 0.739 - ETA: 13s - loss: 0.4734 - accuracy: 0.773 - ETA: 14s - loss: 0.4508 - accuracy: 0.793 - ETA: 15s - loss: 0.4396 - accuracy: 0.796 - ETA: 17s - loss: 0.4421 - accuracy: 0.799 - ETA: 18s - loss: 0.4412 - accuracy: 0.793 - ETA: 18s - loss: 0.4355 - accuracy: 0.791 - ETA: 17s - loss: 0.4261 - accuracy: 0.806 - ETA: 17s - loss: 0.4180 - accuracy: 0.806 - ETA: 17s - loss: 0.4172 - accuracy: 0.809 - ETA: 17s - loss: 0.4132 - accuracy: 0.810 - ETA: 17s - loss: 0.4092 - accuracy: 0.812 - ETA: 16s - loss: 0.4143 - accuracy: 0.802 - ETA: 16s - loss: 0.4087 - accuracy: 0.804 - ETA: 16s - loss: 0.4164 - accuracy: 0.803 - ETA: 16s - loss: 0.4159 - accuracy: 0.802 - ETA: 15s - loss: 0.4167 - accuracy: 0.802 - ETA: 15s - loss: 0.4199 - accuracy: 0.800 - ETA: 15s - loss: 0.4211 - accuracy: 0.797 - ETA: 15s - loss: 0.4277 - accuracy: 0.792 - ETA: 15s - loss: 0.4244 - accuracy: 0.794 - ETA: 15s - loss: 0.4273 - accuracy: 0.794 - ETA: 15s - loss: 0.4383 - accuracy: 0.788 - ETA: 14s - loss: 0.4343 - accuracy: 0.792 - ETA: 14s - loss: 0.4329 - accuracy: 0.791 - ETA: 14s - loss: 0.4330 - accuracy: 0.791 - ETA: 14s - loss: 0.4352 - accuracy: 0.788 - ETA: 14s - loss: 0.4370 - accuracy: 0.791 - ETA: 13s - loss: 0.4374 - accuracy: 0.792 - ETA: 13s - loss: 0.4432 - accuracy: 0.788 - ETA: 13s - loss: 0.4380 - accuracy: 0.790 - ETA: 13s - loss: 0.4366 - accuracy: 0.791 - ETA: 13s - loss: 0.4374 - accuracy: 0.792 - ETA: 13s - loss: 0.4385 - accuracy: 0.789 - ETA: 13s - loss: 0.4394 - accuracy: 0.787 - ETA: 13s - loss: 0.4389 - accuracy: 0.787 - ETA: 12s - loss: 0.4374 - accuracy: 0.789 - ETA: 12s - loss: 0.4385 - accuracy: 0.790 - ETA: 12s - loss: 0.4362 - accuracy: 0.791 - ETA: 12s - loss: 0.4334 - accuracy: 0.794 - ETA: 12s - loss: 0.4308 - accuracy: 0.796 - ETA: 12s - loss: 0.4363 - accuracy: 0.792 - ETA: 11s - loss: 0.4362 - accuracy: 0.793 - ETA: 11s - loss: 0.4343 - accuracy: 0.794 - ETA: 11s - loss: 0.4353 - accuracy: 0.793 - ETA: 11s - loss: 0.4358 - accuracy: 0.791 - ETA: 11s - loss: 0.4330 - accuracy: 0.793 - ETA: 11s - loss: 0.4327 - accuracy: 0.793 - ETA: 10s - loss: 0.4306 - accuracy: 0.795 - ETA: 10s - loss: 0.4327 - accuracy: 0.794 - ETA: 10s - loss: 0.4335 - accuracy: 0.794 - ETA: 10s - loss: 0.4326 - accuracy: 0.794 - ETA: 10s - loss: 0.4384 - accuracy: 0.792 - ETA: 10s - loss: 0.4376 - accuracy: 0.791 - ETA: 10s - loss: 0.4375 - accuracy: 0.791 - ETA: 9s - loss: 0.4360 - accuracy: 0.792 - ETA: 9s - loss: 0.4339 - accuracy: 0.79 - ETA: 9s - loss: 0.4321 - accuracy: 0.79 - ETA: 9s - loss: 0.4342 - accuracy: 0.79 - ETA: 9s - loss: 0.4330 - accuracy: 0.79 - ETA: 9s - loss: 0.4327 - accuracy: 0.79 - ETA: 8s - loss: 0.4336 - accuracy: 0.79 - ETA: 8s - loss: 0.4327 - accuracy: 0.79 - ETA: 8s - loss: 0.4349 - accuracy: 0.79 - ETA: 8s - loss: 0.4331 - accuracy: 0.79 - ETA: 8s - loss: 0.4325 - accuracy: 0.79 - ETA: 8s - loss: 0.4327 - accuracy: 0.79 - ETA: 8s - loss: 0.4343 - accuracy: 0.79 - ETA: 7s - loss: 0.4336 - accuracy: 0.79 - ETA: 7s - loss: 0.4327 - accuracy: 0.79 - ETA: 7s - loss: 0.4323 - accuracy: 0.79 - ETA: 7s - loss: 0.4343 - accuracy: 0.79 - ETA: 7s - loss: 0.4347 - accuracy: 0.79 - ETA: 7s - loss: 0.4359 - accuracy: 0.79 - ETA: 6s - loss: 0.4357 - accuracy: 0.79 - ETA: 6s - loss: 0.4356 - accuracy: 0.79 - ETA: 6s - loss: 0.4348 - accuracy: 0.79 - ETA: 6s - loss: 0.4347 - accuracy: 0.79 - ETA: 6s - loss: 0.4332 - accuracy: 0.79 - ETA: 5s - loss: 0.4330 - accuracy: 0.79 - ETA: 5s - loss: 0.4339 - accuracy: 0.79 - ETA: 5s - loss: 0.4347 - accuracy: 0.78 - ETA: 5s - loss: 0.4352 - accuracy: 0.78 - ETA: 5s - loss: 0.4349 - accuracy: 0.79 - ETA: 5s - loss: 0.4385 - accuracy: 0.78 - ETA: 4s - loss: 0.4386 - accuracy: 0.78 - ETA: 4s - loss: 0.4383 - accuracy: 0.79 - ETA: 4s - loss: 0.4375 - accuracy: 0.79 - ETA: 4s - loss: 0.4370 - accuracy: 0.79 - ETA: 4s - loss: 0.4367 - accuracy: 0.79 - ETA: 4s - loss: 0.4367 - accuracy: 0.79 - ETA: 3s - loss: 0.4362 - accuracy: 0.79 - ETA: 3s - loss: 0.4347 - accuracy: 0.79 - ETA: 3s - loss: 0.4350 - accuracy: 0.79 - ETA: 3s - loss: 0.4342 - accuracy: 0.79 - ETA: 3s - loss: 0.4346 - accuracy: 0.79 - ETA: 3s - loss: 0.4354 - accuracy: 0.79 - ETA: 2s - loss: 0.4344 - accuracy: 0.79 - ETA: 2s - loss: 0.4339 - accuracy: 0.79 - ETA: 2s - loss: 0.4328 - accuracy: 0.79 - ETA: 2s - loss: 0.4345 - accuracy: 0.79 - ETA: 2s - loss: 0.4341 - accuracy: 0.79 - ETA: 1s - loss: 0.4327 - accuracy: 0.79 - ETA: 1s - loss: 0.4330 - accuracy: 0.79 - ETA: 1s - loss: 0.4323 - accuracy: 0.79 - ETA: 1s - loss: 0.4310 - accuracy: 0.79 - ETA: 1s - loss: 0.4303 - accuracy: 0.79 - ETA: 1s - loss: 0.4295 - accuracy: 0.79 - ETA: 0s - loss: 0.4299 - accuracy: 0.79 - ETA: 0s - loss: 0.4293 - accuracy: 0.79 - ETA: 0s - loss: 0.4286 - accuracy: 0.79 - ETA: 0s - loss: 0.4277 - accuracy: 0.79 - ETA: 0s - loss: 0.4291 - accuracy: 0.79 - ETA: 0s - loss: 0.4298 - accuracy: 0.79 - 22s 193ms/step - loss: 0.4298 - accuracy: 0.7972 - val_loss: 0.5655 - val_accuracy: 0.7350\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.4457 - accuracy: 0.81 - ETA: 12s - loss: 0.4730 - accuracy: 0.781 - ETA: 17s - loss: 0.4020 - accuracy: 0.812 - ETA: 17s - loss: 0.3974 - accuracy: 0.828 - ETA: 17s - loss: 0.3736 - accuracy: 0.850 - ETA: 18s - loss: 0.3798 - accuracy: 0.838 - ETA: 18s - loss: 0.3587 - accuracy: 0.857 - ETA: 18s - loss: 0.3564 - accuracy: 0.867 - ETA: 18s - loss: 0.3639 - accuracy: 0.857 - ETA: 18s - loss: 0.3526 - accuracy: 0.865 - ETA: 18s - loss: 0.3509 - accuracy: 0.860 - ETA: 17s - loss: 0.3632 - accuracy: 0.846 - ETA: 17s - loss: 0.3616 - accuracy: 0.843 - ETA: 17s - loss: 0.3728 - accuracy: 0.830 - ETA: 17s - loss: 0.3670 - accuracy: 0.835 - ETA: 18s - loss: 0.3688 - accuracy: 0.835 - ETA: 18s - loss: 0.3635 - accuracy: 0.838 - ETA: 17s - loss: 0.3605 - accuracy: 0.836 - ETA: 17s - loss: 0.3534 - accuracy: 0.845 - ETA: 17s - loss: 0.3507 - accuracy: 0.848 - ETA: 16s - loss: 0.3466 - accuracy: 0.849 - ETA: 16s - loss: 0.3469 - accuracy: 0.852 - ETA: 16s - loss: 0.3481 - accuracy: 0.854 - ETA: 16s - loss: 0.3448 - accuracy: 0.855 - ETA: 15s - loss: 0.3406 - accuracy: 0.856 - ETA: 15s - loss: 0.3503 - accuracy: 0.853 - ETA: 15s - loss: 0.3445 - accuracy: 0.857 - ETA: 15s - loss: 0.3422 - accuracy: 0.859 - ETA: 15s - loss: 0.3375 - accuracy: 0.862 - ETA: 14s - loss: 0.3435 - accuracy: 0.858 - ETA: 14s - loss: 0.3490 - accuracy: 0.852 - ETA: 14s - loss: 0.3498 - accuracy: 0.849 - ETA: 14s - loss: 0.3531 - accuracy: 0.847 - ETA: 14s - loss: 0.3529 - accuracy: 0.846 - ETA: 13s - loss: 0.3617 - accuracy: 0.842 - ETA: 13s - loss: 0.3685 - accuracy: 0.840 - ETA: 13s - loss: 0.3655 - accuracy: 0.841 - ETA: 13s - loss: 0.3687 - accuracy: 0.837 - ETA: 13s - loss: 0.3728 - accuracy: 0.834 - ETA: 13s - loss: 0.3720 - accuracy: 0.835 - ETA: 12s - loss: 0.3710 - accuracy: 0.836 - ETA: 12s - loss: 0.3750 - accuracy: 0.831 - ETA: 12s - loss: 0.3720 - accuracy: 0.834 - ETA: 12s - loss: 0.3736 - accuracy: 0.832 - ETA: 12s - loss: 0.3715 - accuracy: 0.832 - ETA: 12s - loss: 0.3759 - accuracy: 0.830 - ETA: 11s - loss: 0.3725 - accuracy: 0.833 - ETA: 11s - loss: 0.3755 - accuracy: 0.832 - ETA: 11s - loss: 0.3772 - accuracy: 0.830 - ETA: 11s - loss: 0.3804 - accuracy: 0.828 - ETA: 11s - loss: 0.3800 - accuracy: 0.827 - ETA: 11s - loss: 0.3793 - accuracy: 0.828 - ETA: 11s - loss: 0.3790 - accuracy: 0.828 - ETA: 10s - loss: 0.3790 - accuracy: 0.827 - ETA: 10s - loss: 0.3787 - accuracy: 0.827 - ETA: 10s - loss: 0.3808 - accuracy: 0.827 - ETA: 10s - loss: 0.3820 - accuracy: 0.825 - ETA: 10s - loss: 0.3823 - accuracy: 0.824 - ETA: 10s - loss: 0.3835 - accuracy: 0.825 - ETA: 9s - loss: 0.3834 - accuracy: 0.824 - ETA: 9s - loss: 0.3837 - accuracy: 0.82 - ETA: 9s - loss: 0.3833 - accuracy: 0.82 - ETA: 9s - loss: 0.3850 - accuracy: 0.82 - ETA: 9s - loss: 0.3837 - accuracy: 0.82 - ETA: 9s - loss: 0.3861 - accuracy: 0.82 - ETA: 8s - loss: 0.3851 - accuracy: 0.82 - ETA: 8s - loss: 0.3850 - accuracy: 0.82 - ETA: 8s - loss: 0.3852 - accuracy: 0.82 - ETA: 8s - loss: 0.3834 - accuracy: 0.82 - ETA: 8s - loss: 0.3844 - accuracy: 0.82 - ETA: 8s - loss: 0.3874 - accuracy: 0.82 - ETA: 7s - loss: 0.3843 - accuracy: 0.82 - ETA: 7s - loss: 0.3830 - accuracy: 0.82 - ETA: 7s - loss: 0.3846 - accuracy: 0.82 - ETA: 7s - loss: 0.3837 - accuracy: 0.82 - ETA: 7s - loss: 0.3818 - accuracy: 0.82 - ETA: 7s - loss: 0.3816 - accuracy: 0.82 - ETA: 6s - loss: 0.3812 - accuracy: 0.82 - ETA: 6s - loss: 0.3792 - accuracy: 0.82 - ETA: 6s - loss: 0.3789 - accuracy: 0.82 - ETA: 6s - loss: 0.3774 - accuracy: 0.82 - ETA: 6s - loss: 0.3789 - accuracy: 0.82 - ETA: 5s - loss: 0.3793 - accuracy: 0.82 - ETA: 5s - loss: 0.3797 - accuracy: 0.82 - ETA: 5s - loss: 0.3784 - accuracy: 0.82 - ETA: 5s - loss: 0.3777 - accuracy: 0.82 - ETA: 5s - loss: 0.3766 - accuracy: 0.82 - ETA: 5s - loss: 0.3747 - accuracy: 0.82 - ETA: 4s - loss: 0.3794 - accuracy: 0.82 - ETA: 4s - loss: 0.3788 - accuracy: 0.82 - ETA: 4s - loss: 0.3793 - accuracy: 0.82 - ETA: 4s - loss: 0.3813 - accuracy: 0.82 - ETA: 4s - loss: 0.3812 - accuracy: 0.82 - ETA: 3s - loss: 0.3812 - accuracy: 0.82 - ETA: 3s - loss: 0.3812 - accuracy: 0.82 - ETA: 3s - loss: 0.3802 - accuracy: 0.83 - ETA: 3s - loss: 0.3811 - accuracy: 0.82 - ETA: 3s - loss: 0.3793 - accuracy: 0.82 - ETA: 3s - loss: 0.3779 - accuracy: 0.83 - ETA: 2s - loss: 0.3772 - accuracy: 0.83 - ETA: 2s - loss: 0.3786 - accuracy: 0.82 - ETA: 2s - loss: 0.3783 - accuracy: 0.82 - ETA: 2s - loss: 0.3790 - accuracy: 0.82 - ETA: 2s - loss: 0.3793 - accuracy: 0.82 - ETA: 1s - loss: 0.3784 - accuracy: 0.82 - ETA: 1s - loss: 0.3780 - accuracy: 0.83 - ETA: 1s - loss: 0.3784 - accuracy: 0.83 - ETA: 1s - loss: 0.3789 - accuracy: 0.83 - ETA: 1s - loss: 0.3802 - accuracy: 0.82 - ETA: 1s - loss: 0.3813 - accuracy: 0.82 - ETA: 0s - loss: 0.3813 - accuracy: 0.82 - ETA: 0s - loss: 0.3817 - accuracy: 0.82 - ETA: 0s - loss: 0.3842 - accuracy: 0.82 - ETA: 0s - loss: 0.3843 - accuracy: 0.82 - ETA: 0s - loss: 0.3840 - accuracy: 0.82 - ETA: 0s - loss: 0.3849 - accuracy: 0.82 - 23s 196ms/step - loss: 0.3849 - accuracy: 0.8265 - val_loss: 0.4404 - val_accuracy: 0.8039\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.3634 - accuracy: 0.81 - ETA: 14s - loss: 0.3280 - accuracy: 0.859 - ETA: 16s - loss: 0.3624 - accuracy: 0.854 - ETA: 16s - loss: 0.3670 - accuracy: 0.851 - ETA: 17s - loss: 0.3419 - accuracy: 0.862 - ETA: 17s - loss: 0.3306 - accuracy: 0.869 - ETA: 17s - loss: 0.3360 - accuracy: 0.870 - ETA: 17s - loss: 0.3362 - accuracy: 0.871 - ETA: 16s - loss: 0.3315 - accuracy: 0.878 - ETA: 16s - loss: 0.3247 - accuracy: 0.884 - ETA: 16s - loss: 0.3129 - accuracy: 0.889 - ETA: 16s - loss: 0.3274 - accuracy: 0.882 - ETA: 17s - loss: 0.3207 - accuracy: 0.882 - ETA: 17s - loss: 0.3306 - accuracy: 0.872 - ETA: 17s - loss: 0.3256 - accuracy: 0.875 - ETA: 17s - loss: 0.3165 - accuracy: 0.880 - ETA: 17s - loss: 0.3194 - accuracy: 0.878 - ETA: 16s - loss: 0.3164 - accuracy: 0.880 - ETA: 16s - loss: 0.3117 - accuracy: 0.881 - ETA: 16s - loss: 0.3117 - accuracy: 0.876 - ETA: 16s - loss: 0.3150 - accuracy: 0.875 - ETA: 16s - loss: 0.3191 - accuracy: 0.872 - ETA: 16s - loss: 0.3209 - accuracy: 0.869 - ETA: 16s - loss: 0.3188 - accuracy: 0.871 - ETA: 16s - loss: 0.3176 - accuracy: 0.867 - ETA: 15s - loss: 0.3164 - accuracy: 0.867 - ETA: 15s - loss: 0.3148 - accuracy: 0.866 - ETA: 15s - loss: 0.3110 - accuracy: 0.869 - ETA: 15s - loss: 0.3199 - accuracy: 0.865 - ETA: 14s - loss: 0.3203 - accuracy: 0.865 - ETA: 14s - loss: 0.3190 - accuracy: 0.867 - ETA: 14s - loss: 0.3204 - accuracy: 0.866 - ETA: 15s - loss: 0.3217 - accuracy: 0.864 - ETA: 14s - loss: 0.3187 - accuracy: 0.866 - ETA: 14s - loss: 0.3194 - accuracy: 0.867 - ETA: 14s - loss: 0.3192 - accuracy: 0.864 - ETA: 14s - loss: 0.3172 - accuracy: 0.864 - ETA: 13s - loss: 0.3183 - accuracy: 0.863 - ETA: 13s - loss: 0.3175 - accuracy: 0.865 - ETA: 13s - loss: 0.3192 - accuracy: 0.862 - ETA: 13s - loss: 0.3169 - accuracy: 0.864 - ETA: 13s - loss: 0.3152 - accuracy: 0.866 - ETA: 12s - loss: 0.3142 - accuracy: 0.867 - ETA: 12s - loss: 0.3153 - accuracy: 0.865 - ETA: 12s - loss: 0.3141 - accuracy: 0.866 - ETA: 12s - loss: 0.3110 - accuracy: 0.868 - ETA: 12s - loss: 0.3109 - accuracy: 0.866 - ETA: 11s - loss: 0.3111 - accuracy: 0.867 - ETA: 11s - loss: 0.3095 - accuracy: 0.867 - ETA: 11s - loss: 0.3088 - accuracy: 0.867 - ETA: 11s - loss: 0.3097 - accuracy: 0.868 - ETA: 11s - loss: 0.3134 - accuracy: 0.866 - ETA: 10s - loss: 0.3130 - accuracy: 0.867 - ETA: 10s - loss: 0.3129 - accuracy: 0.867 - ETA: 10s - loss: 0.3127 - accuracy: 0.868 - ETA: 10s - loss: 0.3127 - accuracy: 0.867 - ETA: 10s - loss: 0.3119 - accuracy: 0.867 - ETA: 9s - loss: 0.3121 - accuracy: 0.867 - ETA: 9s - loss: 0.3124 - accuracy: 0.86 - ETA: 9s - loss: 0.3137 - accuracy: 0.86 - ETA: 9s - loss: 0.3162 - accuracy: 0.86 - ETA: 9s - loss: 0.3209 - accuracy: 0.86 - ETA: 9s - loss: 0.3193 - accuracy: 0.86 - ETA: 9s - loss: 0.3215 - accuracy: 0.86 - ETA: 8s - loss: 0.3230 - accuracy: 0.86 - ETA: 8s - loss: 0.3258 - accuracy: 0.85 - ETA: 8s - loss: 0.3274 - accuracy: 0.85 - ETA: 8s - loss: 0.3268 - accuracy: 0.85 - ETA: 8s - loss: 0.3280 - accuracy: 0.85 - ETA: 7s - loss: 0.3277 - accuracy: 0.85 - ETA: 7s - loss: 0.3281 - accuracy: 0.85 - ETA: 7s - loss: 0.3266 - accuracy: 0.85 - ETA: 7s - loss: 0.3257 - accuracy: 0.85 - ETA: 7s - loss: 0.3255 - accuracy: 0.85 - ETA: 7s - loss: 0.3278 - accuracy: 0.85 - ETA: 6s - loss: 0.3283 - accuracy: 0.85 - ETA: 6s - loss: 0.3282 - accuracy: 0.85 - ETA: 6s - loss: 0.3282 - accuracy: 0.85 - ETA: 6s - loss: 0.3281 - accuracy: 0.85 - ETA: 6s - loss: 0.3292 - accuracy: 0.85 - ETA: 6s - loss: 0.3285 - accuracy: 0.85 - ETA: 5s - loss: 0.3310 - accuracy: 0.85 - ETA: 5s - loss: 0.3333 - accuracy: 0.85 - ETA: 5s - loss: 0.3347 - accuracy: 0.85 - ETA: 5s - loss: 0.3356 - accuracy: 0.84 - ETA: 5s - loss: 0.3354 - accuracy: 0.84 - ETA: 4s - loss: 0.3365 - accuracy: 0.84 - ETA: 4s - loss: 0.3353 - accuracy: 0.84 - ETA: 4s - loss: 0.3362 - accuracy: 0.84 - ETA: 4s - loss: 0.3349 - accuracy: 0.84 - ETA: 4s - loss: 0.3348 - accuracy: 0.84 - ETA: 4s - loss: 0.3384 - accuracy: 0.84 - ETA: 3s - loss: 0.3383 - accuracy: 0.84 - ETA: 3s - loss: 0.3389 - accuracy: 0.84 - ETA: 3s - loss: 0.3386 - accuracy: 0.84 - ETA: 3s - loss: 0.3388 - accuracy: 0.84 - ETA: 3s - loss: 0.3376 - accuracy: 0.84 - ETA: 3s - loss: 0.3384 - accuracy: 0.84 - ETA: 2s - loss: 0.3391 - accuracy: 0.84 - ETA: 2s - loss: 0.3379 - accuracy: 0.84 - ETA: 2s - loss: 0.3381 - accuracy: 0.84 - ETA: 2s - loss: 0.3369 - accuracy: 0.85 - ETA: 2s - loss: 0.3381 - accuracy: 0.85 - ETA: 2s - loss: 0.3375 - accuracy: 0.85 - ETA: 1s - loss: 0.3402 - accuracy: 0.84 - ETA: 1s - loss: 0.3415 - accuracy: 0.84 - ETA: 1s - loss: 0.3402 - accuracy: 0.85 - ETA: 1s - loss: 0.3405 - accuracy: 0.85 - ETA: 1s - loss: 0.3405 - accuracy: 0.85 - ETA: 1s - loss: 0.3407 - accuracy: 0.85 - ETA: 0s - loss: 0.3406 - accuracy: 0.85 - ETA: 0s - loss: 0.3410 - accuracy: 0.84 - ETA: 0s - loss: 0.3415 - accuracy: 0.84 - ETA: 0s - loss: 0.3425 - accuracy: 0.84 - ETA: 0s - loss: 0.3438 - accuracy: 0.84 - 21s 183ms/step - loss: 0.3432 - accuracy: 0.8484 - val_loss: 0.4144 - val_accuracy: 0.8223\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.3591 - accuracy: 0.81 - ETA: 9s - loss: 0.3364 - accuracy: 0.85 - ETA: 12s - loss: 0.3202 - accuracy: 0.885 - ETA: 13s - loss: 0.3310 - accuracy: 0.867 - ETA: 14s - loss: 0.3186 - accuracy: 0.881 - ETA: 16s - loss: 0.2923 - accuracy: 0.890 - ETA: 17s - loss: 0.2793 - accuracy: 0.901 - ETA: 17s - loss: 0.2656 - accuracy: 0.910 - ETA: 16s - loss: 0.2766 - accuracy: 0.899 - ETA: 16s - loss: 0.2701 - accuracy: 0.909 - ETA: 16s - loss: 0.2709 - accuracy: 0.909 - ETA: 16s - loss: 0.2739 - accuracy: 0.906 - ETA: 16s - loss: 0.2709 - accuracy: 0.906 - ETA: 16s - loss: 0.2827 - accuracy: 0.906 - ETA: 16s - loss: 0.2873 - accuracy: 0.904 - ETA: 15s - loss: 0.2938 - accuracy: 0.900 - ETA: 15s - loss: 0.3040 - accuracy: 0.895 - ETA: 16s - loss: 0.3052 - accuracy: 0.894 - ETA: 16s - loss: 0.3055 - accuracy: 0.891 - ETA: 16s - loss: 0.3073 - accuracy: 0.889 - ETA: 16s - loss: 0.3058 - accuracy: 0.888 - ETA: 15s - loss: 0.2989 - accuracy: 0.890 - ETA: 15s - loss: 0.2922 - accuracy: 0.894 - ETA: 15s - loss: 0.2885 - accuracy: 0.895 - ETA: 15s - loss: 0.2941 - accuracy: 0.892 - ETA: 14s - loss: 0.2921 - accuracy: 0.893 - ETA: 14s - loss: 0.2899 - accuracy: 0.894 - ETA: 14s - loss: 0.2880 - accuracy: 0.892 - ETA: 14s - loss: 0.2912 - accuracy: 0.891 - ETA: 14s - loss: 0.2910 - accuracy: 0.888 - ETA: 14s - loss: 0.2917 - accuracy: 0.887 - ETA: 13s - loss: 0.2902 - accuracy: 0.888 - ETA: 14s - loss: 0.2874 - accuracy: 0.889 - ETA: 13s - loss: 0.2901 - accuracy: 0.887 - ETA: 13s - loss: 0.2938 - accuracy: 0.886 - ETA: 13s - loss: 0.2905 - accuracy: 0.888 - ETA: 13s - loss: 0.2866 - accuracy: 0.891 - ETA: 13s - loss: 0.2852 - accuracy: 0.892 - ETA: 12s - loss: 0.2872 - accuracy: 0.890 - ETA: 12s - loss: 0.2892 - accuracy: 0.889 - ETA: 12s - loss: 0.2901 - accuracy: 0.888 - ETA: 12s - loss: 0.2900 - accuracy: 0.887 - ETA: 12s - loss: 0.2891 - accuracy: 0.888 - ETA: 12s - loss: 0.2898 - accuracy: 0.887 - ETA: 12s - loss: 0.2877 - accuracy: 0.888 - ETA: 11s - loss: 0.2854 - accuracy: 0.889 - ETA: 11s - loss: 0.2835 - accuracy: 0.891 - ETA: 11s - loss: 0.2827 - accuracy: 0.891 - ETA: 11s - loss: 0.2819 - accuracy: 0.891 - ETA: 11s - loss: 0.2837 - accuracy: 0.888 - ETA: 11s - loss: 0.2832 - accuracy: 0.888 - ETA: 10s - loss: 0.2823 - accuracy: 0.888 - ETA: 10s - loss: 0.2807 - accuracy: 0.889 - ETA: 10s - loss: 0.2801 - accuracy: 0.890 - ETA: 10s - loss: 0.2782 - accuracy: 0.892 - ETA: 10s - loss: 0.2802 - accuracy: 0.891 - ETA: 9s - loss: 0.2797 - accuracy: 0.890 - ETA: 9s - loss: 0.2789 - accuracy: 0.89 - ETA: 9s - loss: 0.2799 - accuracy: 0.89 - ETA: 9s - loss: 0.2786 - accuracy: 0.89 - ETA: 9s - loss: 0.2765 - accuracy: 0.89 - ETA: 9s - loss: 0.2752 - accuracy: 0.89 - ETA: 8s - loss: 0.2733 - accuracy: 0.89 - ETA: 8s - loss: 0.2761 - accuracy: 0.89 - ETA: 8s - loss: 0.2764 - accuracy: 0.89 - ETA: 8s - loss: 0.2752 - accuracy: 0.89 - ETA: 8s - loss: 0.2754 - accuracy: 0.89 - ETA: 7s - loss: 0.2768 - accuracy: 0.89 - ETA: 7s - loss: 0.2751 - accuracy: 0.89 - ETA: 7s - loss: 0.2765 - accuracy: 0.89 - ETA: 7s - loss: 0.2762 - accuracy: 0.89 - ETA: 7s - loss: 0.2773 - accuracy: 0.88 - ETA: 7s - loss: 0.2798 - accuracy: 0.88 - ETA: 6s - loss: 0.2819 - accuracy: 0.88 - ETA: 6s - loss: 0.2824 - accuracy: 0.88 - ETA: 6s - loss: 0.2820 - accuracy: 0.88 - ETA: 6s - loss: 0.2821 - accuracy: 0.88 - ETA: 6s - loss: 0.2810 - accuracy: 0.88 - ETA: 6s - loss: 0.2812 - accuracy: 0.88 - ETA: 5s - loss: 0.2813 - accuracy: 0.88 - ETA: 5s - loss: 0.2802 - accuracy: 0.88 - ETA: 5s - loss: 0.2800 - accuracy: 0.88 - ETA: 5s - loss: 0.2803 - accuracy: 0.88 - ETA: 5s - loss: 0.2804 - accuracy: 0.88 - ETA: 5s - loss: 0.2816 - accuracy: 0.88 - ETA: 4s - loss: 0.2814 - accuracy: 0.88 - ETA: 4s - loss: 0.2808 - accuracy: 0.88 - ETA: 4s - loss: 0.2835 - accuracy: 0.88 - ETA: 4s - loss: 0.2837 - accuracy: 0.88 - ETA: 4s - loss: 0.2837 - accuracy: 0.88 - ETA: 4s - loss: 0.2848 - accuracy: 0.88 - ETA: 3s - loss: 0.2831 - accuracy: 0.88 - ETA: 3s - loss: 0.2830 - accuracy: 0.88 - ETA: 3s - loss: 0.2820 - accuracy: 0.88 - ETA: 3s - loss: 0.2809 - accuracy: 0.88 - ETA: 3s - loss: 0.2811 - accuracy: 0.88 - ETA: 3s - loss: 0.2812 - accuracy: 0.88 - ETA: 2s - loss: 0.2817 - accuracy: 0.88 - ETA: 2s - loss: 0.2819 - accuracy: 0.88 - ETA: 2s - loss: 0.2812 - accuracy: 0.88 - ETA: 2s - loss: 0.2812 - accuracy: 0.88 - ETA: 2s - loss: 0.2820 - accuracy: 0.88 - ETA: 2s - loss: 0.2827 - accuracy: 0.88 - ETA: 1s - loss: 0.2826 - accuracy: 0.88 - ETA: 1s - loss: 0.2830 - accuracy: 0.88 - ETA: 1s - loss: 0.2821 - accuracy: 0.88 - ETA: 1s - loss: 0.2816 - accuracy: 0.88 - ETA: 1s - loss: 0.2818 - accuracy: 0.88 - ETA: 1s - loss: 0.2831 - accuracy: 0.88 - ETA: 0s - loss: 0.2821 - accuracy: 0.88 - ETA: 0s - loss: 0.2817 - accuracy: 0.88 - ETA: 0s - loss: 0.2829 - accuracy: 0.88 - ETA: 0s - loss: 0.2828 - accuracy: 0.88 - ETA: 0s - loss: 0.2816 - accuracy: 0.88 - ETA: 0s - loss: 0.2817 - accuracy: 0.88 - ETA: 0s - loss: 0.2814 - accuracy: 0.88 - 21s 182ms/step - loss: 0.2814 - accuracy: 0.8848 - val_loss: 0.4190 - val_accuracy: 0.8261\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.2142 - accuracy: 0.93 - ETA: 9s - loss: 0.2576 - accuracy: 0.89 - ETA: 12s - loss: 0.2700 - accuracy: 0.875 - ETA: 13s - loss: 0.2541 - accuracy: 0.882 - ETA: 14s - loss: 0.2339 - accuracy: 0.893 - ETA: 14s - loss: 0.2246 - accuracy: 0.901 - ETA: 14s - loss: 0.2256 - accuracy: 0.906 - ETA: 15s - loss: 0.2194 - accuracy: 0.910 - ETA: 16s - loss: 0.2236 - accuracy: 0.902 - ETA: 17s - loss: 0.2220 - accuracy: 0.903 - ETA: 18s - loss: 0.2347 - accuracy: 0.900 - ETA: 18s - loss: 0.2386 - accuracy: 0.898 - ETA: 17s - loss: 0.2346 - accuracy: 0.901 - ETA: 17s - loss: 0.2292 - accuracy: 0.906 - ETA: 17s - loss: 0.2425 - accuracy: 0.897 - ETA: 17s - loss: 0.2392 - accuracy: 0.900 - ETA: 16s - loss: 0.2329 - accuracy: 0.904 - ETA: 16s - loss: 0.2315 - accuracy: 0.906 - ETA: 16s - loss: 0.2321 - accuracy: 0.906 - ETA: 16s - loss: 0.2292 - accuracy: 0.907 - ETA: 16s - loss: 0.2268 - accuracy: 0.910 - ETA: 16s - loss: 0.2285 - accuracy: 0.910 - ETA: 15s - loss: 0.2363 - accuracy: 0.907 - ETA: 15s - loss: 0.2350 - accuracy: 0.907 - ETA: 15s - loss: 0.2384 - accuracy: 0.903 - ETA: 15s - loss: 0.2372 - accuracy: 0.903 - ETA: 15s - loss: 0.2382 - accuracy: 0.902 - ETA: 15s - loss: 0.2364 - accuracy: 0.904 - ETA: 15s - loss: 0.2379 - accuracy: 0.904 - ETA: 15s - loss: 0.2343 - accuracy: 0.905 - ETA: 15s - loss: 0.2318 - accuracy: 0.906 - ETA: 14s - loss: 0.2402 - accuracy: 0.898 - ETA: 14s - loss: 0.2382 - accuracy: 0.898 - ETA: 14s - loss: 0.2392 - accuracy: 0.899 - ETA: 14s - loss: 0.2345 - accuracy: 0.902 - ETA: 14s - loss: 0.2379 - accuracy: 0.900 - ETA: 14s - loss: 0.2387 - accuracy: 0.901 - ETA: 14s - loss: 0.2372 - accuracy: 0.901 - ETA: 14s - loss: 0.2380 - accuracy: 0.899 - ETA: 13s - loss: 0.2393 - accuracy: 0.900 - ETA: 13s - loss: 0.2354 - accuracy: 0.902 - ETA: 13s - loss: 0.2333 - accuracy: 0.904 - ETA: 13s - loss: 0.2369 - accuracy: 0.903 - ETA: 13s - loss: 0.2348 - accuracy: 0.904 - ETA: 12s - loss: 0.2356 - accuracy: 0.903 - ETA: 12s - loss: 0.2393 - accuracy: 0.902 - ETA: 12s - loss: 0.2383 - accuracy: 0.902 - ETA: 12s - loss: 0.2382 - accuracy: 0.901 - ETA: 12s - loss: 0.2377 - accuracy: 0.902 - ETA: 11s - loss: 0.2377 - accuracy: 0.902 - ETA: 11s - loss: 0.2359 - accuracy: 0.903 - ETA: 11s - loss: 0.2362 - accuracy: 0.903 - ETA: 11s - loss: 0.2360 - accuracy: 0.903 - ETA: 11s - loss: 0.2353 - accuracy: 0.903 - ETA: 11s - loss: 0.2408 - accuracy: 0.901 - ETA: 10s - loss: 0.2421 - accuracy: 0.901 - ETA: 10s - loss: 0.2403 - accuracy: 0.902 - ETA: 10s - loss: 0.2414 - accuracy: 0.901 - ETA: 10s - loss: 0.2421 - accuracy: 0.901 - ETA: 10s - loss: 0.2401 - accuracy: 0.902 - ETA: 10s - loss: 0.2407 - accuracy: 0.902 - ETA: 9s - loss: 0.2397 - accuracy: 0.902 - ETA: 9s - loss: 0.2403 - accuracy: 0.90 - ETA: 9s - loss: 0.2406 - accuracy: 0.89 - ETA: 9s - loss: 0.2395 - accuracy: 0.90 - ETA: 9s - loss: 0.2396 - accuracy: 0.90 - ETA: 8s - loss: 0.2398 - accuracy: 0.90 - ETA: 8s - loss: 0.2411 - accuracy: 0.90 - ETA: 8s - loss: 0.2396 - accuracy: 0.90 - ETA: 8s - loss: 0.2399 - accuracy: 0.90 - ETA: 8s - loss: 0.2380 - accuracy: 0.90 - ETA: 7s - loss: 0.2368 - accuracy: 0.90 - ETA: 7s - loss: 0.2369 - accuracy: 0.90 - ETA: 7s - loss: 0.2355 - accuracy: 0.90 - ETA: 7s - loss: 0.2357 - accuracy: 0.90 - ETA: 7s - loss: 0.2358 - accuracy: 0.90 - ETA: 7s - loss: 0.2365 - accuracy: 0.90 - ETA: 6s - loss: 0.2373 - accuracy: 0.90 - ETA: 6s - loss: 0.2375 - accuracy: 0.90 - ETA: 6s - loss: 0.2384 - accuracy: 0.90 - ETA: 6s - loss: 0.2419 - accuracy: 0.89 - ETA: 6s - loss: 0.2408 - accuracy: 0.89 - ETA: 6s - loss: 0.2409 - accuracy: 0.89 - ETA: 5s - loss: 0.2410 - accuracy: 0.89 - ETA: 5s - loss: 0.2408 - accuracy: 0.89 - ETA: 5s - loss: 0.2404 - accuracy: 0.89 - ETA: 5s - loss: 0.2417 - accuracy: 0.89 - ETA: 5s - loss: 0.2424 - accuracy: 0.89 - ETA: 4s - loss: 0.2423 - accuracy: 0.89 - ETA: 4s - loss: 0.2429 - accuracy: 0.89 - ETA: 4s - loss: 0.2422 - accuracy: 0.89 - ETA: 4s - loss: 0.2424 - accuracy: 0.89 - ETA: 4s - loss: 0.2425 - accuracy: 0.89 - ETA: 4s - loss: 0.2423 - accuracy: 0.89 - ETA: 3s - loss: 0.2427 - accuracy: 0.89 - ETA: 3s - loss: 0.2422 - accuracy: 0.89 - ETA: 3s - loss: 0.2429 - accuracy: 0.89 - ETA: 3s - loss: 0.2425 - accuracy: 0.89 - ETA: 3s - loss: 0.2433 - accuracy: 0.89 - ETA: 2s - loss: 0.2428 - accuracy: 0.89 - ETA: 2s - loss: 0.2431 - accuracy: 0.89 - ETA: 2s - loss: 0.2447 - accuracy: 0.89 - ETA: 2s - loss: 0.2468 - accuracy: 0.89 - ETA: 2s - loss: 0.2464 - accuracy: 0.89 - ETA: 2s - loss: 0.2465 - accuracy: 0.89 - ETA: 1s - loss: 0.2466 - accuracy: 0.89 - ETA: 1s - loss: 0.2467 - accuracy: 0.89 - ETA: 1s - loss: 0.2461 - accuracy: 0.89 - ETA: 1s - loss: 0.2471 - accuracy: 0.89 - ETA: 1s - loss: 0.2484 - accuracy: 0.89 - ETA: 0s - loss: 0.2484 - accuracy: 0.89 - ETA: 0s - loss: 0.2485 - accuracy: 0.89 - ETA: 0s - loss: 0.2493 - accuracy: 0.89 - ETA: 0s - loss: 0.2499 - accuracy: 0.89 - ETA: 0s - loss: 0.2492 - accuracy: 0.89 - ETA: 0s - loss: 0.2488 - accuracy: 0.89 - 23s 200ms/step - loss: 0.2488 - accuracy: 0.8975 - val_loss: 0.4493 - val_accuracy: 0.8185\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.1912 - accuracy: 0.90 - ETA: 9s - loss: 0.1960 - accuracy: 0.90 - ETA: 13s - loss: 0.1774 - accuracy: 0.927 - ETA: 14s - loss: 0.1617 - accuracy: 0.937 - ETA: 15s - loss: 0.1855 - accuracy: 0.937 - ETA: 15s - loss: 0.1798 - accuracy: 0.932 - ETA: 15s - loss: 0.1756 - accuracy: 0.933 - ETA: 16s - loss: 0.1789 - accuracy: 0.929 - ETA: 16s - loss: 0.1835 - accuracy: 0.930 - ETA: 16s - loss: 0.1871 - accuracy: 0.925 - ETA: 16s - loss: 0.1769 - accuracy: 0.931 - ETA: 16s - loss: 0.1741 - accuracy: 0.934 - ETA: 16s - loss: 0.1708 - accuracy: 0.935 - ETA: 16s - loss: 0.1690 - accuracy: 0.935 - ETA: 15s - loss: 0.1655 - accuracy: 0.939 - ETA: 15s - loss: 0.1630 - accuracy: 0.939 - ETA: 16s - loss: 0.1647 - accuracy: 0.937 - ETA: 15s - loss: 0.1688 - accuracy: 0.935 - ETA: 15s - loss: 0.1692 - accuracy: 0.934 - ETA: 15s - loss: 0.1784 - accuracy: 0.929 - ETA: 15s - loss: 0.1797 - accuracy: 0.928 - ETA: 15s - loss: 0.1885 - accuracy: 0.924 - ETA: 15s - loss: 0.1910 - accuracy: 0.923 - ETA: 15s - loss: 0.1900 - accuracy: 0.924 - ETA: 15s - loss: 0.1929 - accuracy: 0.920 - ETA: 15s - loss: 0.1914 - accuracy: 0.920 - ETA: 14s - loss: 0.2010 - accuracy: 0.919 - ETA: 14s - loss: 0.2077 - accuracy: 0.918 - ETA: 14s - loss: 0.2065 - accuracy: 0.919 - ETA: 14s - loss: 0.2025 - accuracy: 0.921 - ETA: 14s - loss: 0.2021 - accuracy: 0.921 - ETA: 14s - loss: 0.2004 - accuracy: 0.922 - ETA: 13s - loss: 0.1994 - accuracy: 0.922 - ETA: 13s - loss: 0.2007 - accuracy: 0.922 - ETA: 13s - loss: 0.1985 - accuracy: 0.924 - ETA: 13s - loss: 0.1986 - accuracy: 0.921 - ETA: 13s - loss: 0.1989 - accuracy: 0.921 - ETA: 13s - loss: 0.1974 - accuracy: 0.921 - ETA: 12s - loss: 0.2002 - accuracy: 0.921 - ETA: 12s - loss: 0.1998 - accuracy: 0.921 - ETA: 12s - loss: 0.1978 - accuracy: 0.922 - ETA: 12s - loss: 0.1976 - accuracy: 0.921 - ETA: 12s - loss: 0.2000 - accuracy: 0.920 - ETA: 12s - loss: 0.1979 - accuracy: 0.921 - ETA: 11s - loss: 0.1948 - accuracy: 0.922 - ETA: 11s - loss: 0.1958 - accuracy: 0.921 - ETA: 11s - loss: 0.1938 - accuracy: 0.922 - ETA: 11s - loss: 0.1922 - accuracy: 0.923 - ETA: 11s - loss: 0.1925 - accuracy: 0.924 - ETA: 10s - loss: 0.1914 - accuracy: 0.924 - ETA: 10s - loss: 0.1904 - accuracy: 0.925 - ETA: 10s - loss: 0.1897 - accuracy: 0.925 - ETA: 10s - loss: 0.1914 - accuracy: 0.924 - ETA: 10s - loss: 0.1908 - accuracy: 0.924 - ETA: 10s - loss: 0.1923 - accuracy: 0.924 - ETA: 9s - loss: 0.1918 - accuracy: 0.924 - ETA: 9s - loss: 0.1939 - accuracy: 0.92 - ETA: 9s - loss: 0.1919 - accuracy: 0.92 - ETA: 9s - loss: 0.1907 - accuracy: 0.92 - ETA: 9s - loss: 0.1917 - accuracy: 0.92 - ETA: 9s - loss: 0.1937 - accuracy: 0.92 - ETA: 8s - loss: 0.1938 - accuracy: 0.92 - ETA: 8s - loss: 0.1964 - accuracy: 0.92 - ETA: 8s - loss: 0.1969 - accuracy: 0.92 - ETA: 8s - loss: 0.1985 - accuracy: 0.92 - ETA: 8s - loss: 0.1975 - accuracy: 0.92 - ETA: 8s - loss: 0.1980 - accuracy: 0.92 - ETA: 7s - loss: 0.1985 - accuracy: 0.92 - ETA: 7s - loss: 0.1969 - accuracy: 0.92 - ETA: 7s - loss: 0.1968 - accuracy: 0.92 - ETA: 7s - loss: 0.1981 - accuracy: 0.92 - ETA: 7s - loss: 0.2002 - accuracy: 0.92 - ETA: 7s - loss: 0.1987 - accuracy: 0.92 - ETA: 7s - loss: 0.2002 - accuracy: 0.92 - ETA: 6s - loss: 0.1992 - accuracy: 0.92 - ETA: 6s - loss: 0.2002 - accuracy: 0.92 - ETA: 6s - loss: 0.2025 - accuracy: 0.92 - ETA: 6s - loss: 0.2049 - accuracy: 0.91 - ETA: 6s - loss: 0.2045 - accuracy: 0.92 - ETA: 6s - loss: 0.2041 - accuracy: 0.92 - ETA: 5s - loss: 0.2050 - accuracy: 0.92 - ETA: 5s - loss: 0.2069 - accuracy: 0.91 - ETA: 5s - loss: 0.2077 - accuracy: 0.91 - ETA: 5s - loss: 0.2074 - accuracy: 0.91 - ETA: 5s - loss: 0.2062 - accuracy: 0.92 - ETA: 5s - loss: 0.2080 - accuracy: 0.91 - ETA: 4s - loss: 0.2085 - accuracy: 0.91 - ETA: 4s - loss: 0.2077 - accuracy: 0.92 - ETA: 4s - loss: 0.2078 - accuracy: 0.92 - ETA: 4s - loss: 0.2114 - accuracy: 0.91 - ETA: 4s - loss: 0.2114 - accuracy: 0.91 - ETA: 4s - loss: 0.2129 - accuracy: 0.91 - ETA: 3s - loss: 0.2120 - accuracy: 0.91 - ETA: 3s - loss: 0.2139 - accuracy: 0.91 - ETA: 3s - loss: 0.2143 - accuracy: 0.91 - ETA: 3s - loss: 0.2148 - accuracy: 0.91 - ETA: 3s - loss: 0.2145 - accuracy: 0.91 - ETA: 3s - loss: 0.2159 - accuracy: 0.91 - ETA: 2s - loss: 0.2180 - accuracy: 0.91 - ETA: 2s - loss: 0.2173 - accuracy: 0.91 - ETA: 2s - loss: 0.2169 - accuracy: 0.91 - ETA: 2s - loss: 0.2166 - accuracy: 0.91 - ETA: 2s - loss: 0.2174 - accuracy: 0.91 - ETA: 2s - loss: 0.2171 - accuracy: 0.91 - ETA: 1s - loss: 0.2174 - accuracy: 0.91 - ETA: 1s - loss: 0.2178 - accuracy: 0.91 - ETA: 1s - loss: 0.2165 - accuracy: 0.91 - ETA: 1s - loss: 0.2166 - accuracy: 0.91 - ETA: 1s - loss: 0.2169 - accuracy: 0.91 - ETA: 1s - loss: 0.2168 - accuracy: 0.91 - ETA: 0s - loss: 0.2179 - accuracy: 0.91 - ETA: 0s - loss: 0.2178 - accuracy: 0.91 - ETA: 0s - loss: 0.2177 - accuracy: 0.91 - ETA: 0s - loss: 0.2174 - accuracy: 0.91 - ETA: 0s - loss: 0.2175 - accuracy: 0.91 - 21s 179ms/step - loss: 0.2182 - accuracy: 0.9138 - val_loss: 0.4471 - val_accuracy: 0.8349\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.90 - ETA: 8s - loss: 0.1095 - accuracy: 0.95 - ETA: 11s - loss: 0.1401 - accuracy: 0.947 - ETA: 12s - loss: 0.1228 - accuracy: 0.953 - ETA: 13s - loss: 0.1206 - accuracy: 0.962 - ETA: 14s - loss: 0.1503 - accuracy: 0.932 - ETA: 14s - loss: 0.1489 - accuracy: 0.933 - ETA: 14s - loss: 0.1539 - accuracy: 0.925 - ETA: 14s - loss: 0.1475 - accuracy: 0.927 - ETA: 14s - loss: 0.1482 - accuracy: 0.931 - ETA: 14s - loss: 0.1456 - accuracy: 0.931 - ETA: 14s - loss: 0.1519 - accuracy: 0.929 - ETA: 14s - loss: 0.1491 - accuracy: 0.932 - ETA: 15s - loss: 0.1460 - accuracy: 0.933 - ETA: 15s - loss: 0.1514 - accuracy: 0.931 - ETA: 15s - loss: 0.1503 - accuracy: 0.929 - ETA: 15s - loss: 0.1472 - accuracy: 0.932 - ETA: 14s - loss: 0.1505 - accuracy: 0.928 - ETA: 14s - loss: 0.1464 - accuracy: 0.932 - ETA: 14s - loss: 0.1592 - accuracy: 0.926 - ETA: 14s - loss: 0.1623 - accuracy: 0.927 - ETA: 14s - loss: 0.1604 - accuracy: 0.927 - ETA: 14s - loss: 0.1564 - accuracy: 0.929 - ETA: 14s - loss: 0.1569 - accuracy: 0.929 - ETA: 14s - loss: 0.1597 - accuracy: 0.930 - ETA: 14s - loss: 0.1634 - accuracy: 0.927 - ETA: 14s - loss: 0.1619 - accuracy: 0.929 - ETA: 14s - loss: 0.1613 - accuracy: 0.929 - ETA: 14s - loss: 0.1632 - accuracy: 0.927 - ETA: 14s - loss: 0.1604 - accuracy: 0.929 - ETA: 14s - loss: 0.1600 - accuracy: 0.929 - ETA: 14s - loss: 0.1637 - accuracy: 0.927 - ETA: 14s - loss: 0.1629 - accuracy: 0.927 - ETA: 13s - loss: 0.1616 - accuracy: 0.928 - ETA: 13s - loss: 0.1633 - accuracy: 0.928 - ETA: 13s - loss: 0.1611 - accuracy: 0.930 - ETA: 13s - loss: 0.1646 - accuracy: 0.929 - ETA: 13s - loss: 0.1650 - accuracy: 0.929 - ETA: 13s - loss: 0.1640 - accuracy: 0.930 - ETA: 12s - loss: 0.1650 - accuracy: 0.930 - ETA: 12s - loss: 0.1644 - accuracy: 0.931 - ETA: 12s - loss: 0.1630 - accuracy: 0.933 - ETA: 12s - loss: 0.1632 - accuracy: 0.932 - ETA: 12s - loss: 0.1639 - accuracy: 0.932 - ETA: 12s - loss: 0.1643 - accuracy: 0.931 - ETA: 11s - loss: 0.1653 - accuracy: 0.931 - ETA: 11s - loss: 0.1640 - accuracy: 0.932 - ETA: 11s - loss: 0.1642 - accuracy: 0.931 - ETA: 11s - loss: 0.1629 - accuracy: 0.933 - ETA: 11s - loss: 0.1631 - accuracy: 0.932 - ETA: 10s - loss: 0.1633 - accuracy: 0.931 - ETA: 10s - loss: 0.1629 - accuracy: 0.931 - ETA: 10s - loss: 0.1612 - accuracy: 0.932 - ETA: 10s - loss: 0.1595 - accuracy: 0.933 - ETA: 10s - loss: 0.1603 - accuracy: 0.932 - ETA: 10s - loss: 0.1607 - accuracy: 0.931 - ETA: 9s - loss: 0.1611 - accuracy: 0.932 - ETA: 9s - loss: 0.1613 - accuracy: 0.93 - ETA: 9s - loss: 0.1608 - accuracy: 0.93 - ETA: 9s - loss: 0.1593 - accuracy: 0.93 - ETA: 9s - loss: 0.1607 - accuracy: 0.93 - ETA: 8s - loss: 0.1598 - accuracy: 0.93 - ETA: 8s - loss: 0.1610 - accuracy: 0.93 - ETA: 8s - loss: 0.1607 - accuracy: 0.93 - ETA: 8s - loss: 0.1596 - accuracy: 0.93 - ETA: 8s - loss: 0.1598 - accuracy: 0.93 - ETA: 8s - loss: 0.1596 - accuracy: 0.93 - ETA: 7s - loss: 0.1593 - accuracy: 0.93 - ETA: 7s - loss: 0.1598 - accuracy: 0.93 - ETA: 7s - loss: 0.1626 - accuracy: 0.93 - ETA: 7s - loss: 0.1613 - accuracy: 0.93 - ETA: 7s - loss: 0.1606 - accuracy: 0.93 - ETA: 7s - loss: 0.1601 - accuracy: 0.93 - ETA: 6s - loss: 0.1605 - accuracy: 0.93 - ETA: 6s - loss: 0.1603 - accuracy: 0.93 - ETA: 6s - loss: 0.1621 - accuracy: 0.93 - ETA: 6s - loss: 0.1636 - accuracy: 0.92 - ETA: 6s - loss: 0.1627 - accuracy: 0.93 - ETA: 6s - loss: 0.1642 - accuracy: 0.93 - ETA: 5s - loss: 0.1637 - accuracy: 0.93 - ETA: 5s - loss: 0.1648 - accuracy: 0.93 - ETA: 5s - loss: 0.1655 - accuracy: 0.92 - ETA: 5s - loss: 0.1668 - accuracy: 0.92 - ETA: 5s - loss: 0.1666 - accuracy: 0.92 - ETA: 5s - loss: 0.1669 - accuracy: 0.92 - ETA: 4s - loss: 0.1673 - accuracy: 0.92 - ETA: 4s - loss: 0.1686 - accuracy: 0.92 - ETA: 4s - loss: 0.1698 - accuracy: 0.92 - ETA: 4s - loss: 0.1711 - accuracy: 0.92 - ETA: 4s - loss: 0.1714 - accuracy: 0.92 - ETA: 4s - loss: 0.1711 - accuracy: 0.92 - ETA: 3s - loss: 0.1706 - accuracy: 0.92 - ETA: 3s - loss: 0.1720 - accuracy: 0.92 - ETA: 3s - loss: 0.1706 - accuracy: 0.92 - ETA: 3s - loss: 0.1709 - accuracy: 0.92 - ETA: 3s - loss: 0.1711 - accuracy: 0.92 - ETA: 3s - loss: 0.1706 - accuracy: 0.92 - ETA: 2s - loss: 0.1704 - accuracy: 0.92 - ETA: 2s - loss: 0.1700 - accuracy: 0.92 - ETA: 2s - loss: 0.1709 - accuracy: 0.92 - ETA: 2s - loss: 0.1711 - accuracy: 0.92 - ETA: 2s - loss: 0.1709 - accuracy: 0.92 - ETA: 2s - loss: 0.1711 - accuracy: 0.92 - ETA: 1s - loss: 0.1724 - accuracy: 0.92 - ETA: 1s - loss: 0.1727 - accuracy: 0.92 - ETA: 1s - loss: 0.1728 - accuracy: 0.92 - ETA: 1s - loss: 0.1726 - accuracy: 0.92 - ETA: 1s - loss: 0.1729 - accuracy: 0.92 - ETA: 1s - loss: 0.1733 - accuracy: 0.92 - ETA: 0s - loss: 0.1729 - accuracy: 0.92 - ETA: 0s - loss: 0.1758 - accuracy: 0.92 - ETA: 0s - loss: 0.1759 - accuracy: 0.92 - ETA: 0s - loss: 0.1757 - accuracy: 0.92 - ETA: 0s - loss: 0.1755 - accuracy: 0.92 - ETA: 0s - loss: 0.1766 - accuracy: 0.92 - ETA: 0s - loss: 0.1766 - accuracy: 0.92 - 21s 179ms/step - loss: 0.1766 - accuracy: 0.9243 - val_loss: 0.5317 - val_accuracy: 0.8273\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.1453 - accuracy: 0.93 - ETA: 10s - loss: 0.1246 - accuracy: 0.937 - ETA: 13s - loss: 0.1297 - accuracy: 0.937 - ETA: 14s - loss: 0.1834 - accuracy: 0.914 - ETA: 15s - loss: 0.1675 - accuracy: 0.918 - ETA: 15s - loss: 0.1714 - accuracy: 0.911 - ETA: 15s - loss: 0.1655 - accuracy: 0.919 - ETA: 15s - loss: 0.1594 - accuracy: 0.925 - ETA: 16s - loss: 0.1568 - accuracy: 0.930 - ETA: 16s - loss: 0.1507 - accuracy: 0.937 - ETA: 16s - loss: 0.1504 - accuracy: 0.934 - ETA: 16s - loss: 0.1501 - accuracy: 0.934 - ETA: 15s - loss: 0.1572 - accuracy: 0.932 - ETA: 15s - loss: 0.1511 - accuracy: 0.937 - ETA: 15s - loss: 0.1499 - accuracy: 0.939 - ETA: 15s - loss: 0.1517 - accuracy: 0.937 - ETA: 15s - loss: 0.1511 - accuracy: 0.937 - ETA: 15s - loss: 0.1570 - accuracy: 0.934 - ETA: 15s - loss: 0.1544 - accuracy: 0.937 - ETA: 15s - loss: 0.1496 - accuracy: 0.940 - ETA: 15s - loss: 0.1544 - accuracy: 0.939 - ETA: 15s - loss: 0.1489 - accuracy: 0.941 - ETA: 14s - loss: 0.1453 - accuracy: 0.944 - ETA: 14s - loss: 0.1451 - accuracy: 0.945 - ETA: 14s - loss: 0.1499 - accuracy: 0.942 - ETA: 14s - loss: 0.1473 - accuracy: 0.943 - ETA: 14s - loss: 0.1494 - accuracy: 0.942 - ETA: 14s - loss: 0.1470 - accuracy: 0.943 - ETA: 14s - loss: 0.1462 - accuracy: 0.941 - ETA: 13s - loss: 0.1514 - accuracy: 0.940 - ETA: 13s - loss: 0.1508 - accuracy: 0.940 - ETA: 13s - loss: 0.1499 - accuracy: 0.940 - ETA: 13s - loss: 0.1487 - accuracy: 0.941 - ETA: 13s - loss: 0.1503 - accuracy: 0.939 - ETA: 13s - loss: 0.1506 - accuracy: 0.937 - ETA: 13s - loss: 0.1505 - accuracy: 0.937 - ETA: 12s - loss: 0.1494 - accuracy: 0.939 - ETA: 12s - loss: 0.1514 - accuracy: 0.938 - ETA: 12s - loss: 0.1523 - accuracy: 0.938 - ETA: 12s - loss: 0.1529 - accuracy: 0.937 - ETA: 12s - loss: 0.1522 - accuracy: 0.937 - ETA: 12s - loss: 0.1511 - accuracy: 0.937 - ETA: 12s - loss: 0.1496 - accuracy: 0.938 - ETA: 12s - loss: 0.1494 - accuracy: 0.938 - ETA: 11s - loss: 0.1481 - accuracy: 0.939 - ETA: 11s - loss: 0.1495 - accuracy: 0.938 - ETA: 11s - loss: 0.1490 - accuracy: 0.938 - ETA: 11s - loss: 0.1484 - accuracy: 0.939 - ETA: 11s - loss: 0.1467 - accuracy: 0.940 - ETA: 11s - loss: 0.1460 - accuracy: 0.940 - ETA: 11s - loss: 0.1453 - accuracy: 0.941 - ETA: 10s - loss: 0.1443 - accuracy: 0.941 - ETA: 10s - loss: 0.1448 - accuracy: 0.941 - ETA: 10s - loss: 0.1440 - accuracy: 0.941 - ETA: 10s - loss: 0.1452 - accuracy: 0.940 - ETA: 10s - loss: 0.1437 - accuracy: 0.940 - ETA: 10s - loss: 0.1424 - accuracy: 0.941 - ETA: 9s - loss: 0.1418 - accuracy: 0.942 - ETA: 9s - loss: 0.1422 - accuracy: 0.94 - ETA: 9s - loss: 0.1431 - accuracy: 0.94 - ETA: 9s - loss: 0.1425 - accuracy: 0.94 - ETA: 9s - loss: 0.1417 - accuracy: 0.94 - ETA: 8s - loss: 0.1407 - accuracy: 0.94 - ETA: 8s - loss: 0.1397 - accuracy: 0.94 - ETA: 8s - loss: 0.1396 - accuracy: 0.94 - ETA: 8s - loss: 0.1394 - accuracy: 0.94 - ETA: 8s - loss: 0.1389 - accuracy: 0.94 - ETA: 8s - loss: 0.1391 - accuracy: 0.94 - ETA: 7s - loss: 0.1383 - accuracy: 0.94 - ETA: 7s - loss: 0.1387 - accuracy: 0.94 - ETA: 7s - loss: 0.1372 - accuracy: 0.94 - ETA: 7s - loss: 0.1369 - accuracy: 0.94 - ETA: 7s - loss: 0.1368 - accuracy: 0.94 - ETA: 7s - loss: 0.1371 - accuracy: 0.94 - ETA: 6s - loss: 0.1374 - accuracy: 0.94 - ETA: 6s - loss: 0.1375 - accuracy: 0.94 - ETA: 6s - loss: 0.1378 - accuracy: 0.94 - ETA: 6s - loss: 0.1373 - accuracy: 0.94 - ETA: 6s - loss: 0.1376 - accuracy: 0.94 - ETA: 6s - loss: 0.1368 - accuracy: 0.94 - ETA: 5s - loss: 0.1379 - accuracy: 0.94 - ETA: 5s - loss: 0.1371 - accuracy: 0.94 - ETA: 5s - loss: 0.1373 - accuracy: 0.94 - ETA: 5s - loss: 0.1371 - accuracy: 0.94 - ETA: 5s - loss: 0.1361 - accuracy: 0.94 - ETA: 5s - loss: 0.1362 - accuracy: 0.94 - ETA: 4s - loss: 0.1356 - accuracy: 0.94 - ETA: 4s - loss: 0.1344 - accuracy: 0.94 - ETA: 4s - loss: 0.1343 - accuracy: 0.94 - ETA: 4s - loss: 0.1348 - accuracy: 0.94 - ETA: 4s - loss: 0.1346 - accuracy: 0.94 - ETA: 4s - loss: 0.1345 - accuracy: 0.94 - ETA: 3s - loss: 0.1337 - accuracy: 0.94 - ETA: 3s - loss: 0.1340 - accuracy: 0.94 - ETA: 3s - loss: 0.1340 - accuracy: 0.94 - ETA: 3s - loss: 0.1335 - accuracy: 0.94 - ETA: 3s - loss: 0.1332 - accuracy: 0.94 - ETA: 3s - loss: 0.1329 - accuracy: 0.94 - ETA: 2s - loss: 0.1324 - accuracy: 0.94 - ETA: 2s - loss: 0.1331 - accuracy: 0.94 - ETA: 2s - loss: 0.1327 - accuracy: 0.94 - ETA: 2s - loss: 0.1334 - accuracy: 0.94 - ETA: 2s - loss: 0.1338 - accuracy: 0.94 - ETA: 2s - loss: 0.1341 - accuracy: 0.94 - ETA: 1s - loss: 0.1341 - accuracy: 0.94 - ETA: 1s - loss: 0.1346 - accuracy: 0.94 - ETA: 1s - loss: 0.1341 - accuracy: 0.94 - ETA: 1s - loss: 0.1332 - accuracy: 0.94 - ETA: 1s - loss: 0.1329 - accuracy: 0.94 - ETA: 1s - loss: 0.1322 - accuracy: 0.94 - ETA: 0s - loss: 0.1318 - accuracy: 0.94 - ETA: 0s - loss: 0.1326 - accuracy: 0.94 - ETA: 0s - loss: 0.1322 - accuracy: 0.94 - ETA: 0s - loss: 0.1330 - accuracy: 0.94 - ETA: 0s - loss: 0.1330 - accuracy: 0.94 - ETA: 0s - loss: 0.1330 - accuracy: 0.94 - 22s 186ms/step - loss: 0.1330 - accuracy: 0.9452 - val_loss: 0.5306 - val_accuracy: 0.8343\n",
      "WARNING:tensorflow:From C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: EasternWestern_model\\assets\n"
     ]
    }
   ],
   "source": [
    "trainModel(X,y) #pass features and labels for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2V6ASW52VpFM"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "IMG_SIZE=60\n",
    "CATEGORIES = [\"Eastern\", \"Western\"]\n",
    "\n",
    "def computeCategory(imagePath,model):\n",
    "    files = glob.glob(imagePath)\n",
    "    print(files) #displays query file name\n",
    "    i=0\n",
    "    x=[]\n",
    "    filenames=[]\n",
    "    for myFile in files:\n",
    "        filenames.append(myFile) #append image in array\n",
    "        image = cv2.imread(myFile,cv2.IMREAD_GRAYSCALE) #read image and convert into black & white\n",
    "        image = cv2.resize(image,(IMG_SIZE,IMG_SIZE)) #resize image to 60x60\n",
    "        x.append(image) #append resized image in array\n",
    "        \n",
    "        X_data=np.array(x) #convert array that contains image to numpy array for prediction\n",
    "        X_data = X_data.reshape((-1, IMG_SIZE, IMG_SIZE, 1)) #-1 is for features, resize image to 60x60, 1 is for grayscale\n",
    "        X_data = X_data/ 255.0 #scale data by dividing by max value\n",
    "        p = model.predict(X_data) #pass the image to the model for prediction\n",
    "        print(p)\n",
    "        label = CATEGORIES[int(np.round(p[0]))] # 0=top, 1=bottom. Round the float and convert to into to get either 0 or 1\n",
    "        print(label)\n",
    "        return label #return predicted label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DVpHQW6L8biJ",
    "outputId": "b615c7e6-95f4-41c0-935b-775972a5e65b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/content/Capture1.PNG']\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8add0bc320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[0.18604608]]\n",
      "Eastern\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "mod=keras.models.load_model(\"EasternWestern_model\")\n",
    "category=\"\"\n",
    "imagePath=\"/content/Capture1.PNG\"\n",
    "category==computeCategory(imagePath,mod)\n",
    "print(category)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "EasternWestern.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
